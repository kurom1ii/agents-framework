# Agents Framework

Framework Python nháº¹ cho multi-agent orchestration vá»›i tÃ­ch há»£p MCP.

## TÃ­nh nÄƒng chÃ­nh

- ğŸ¤– **Multi-Agent Teams** - Supervisor, Worker, Router patterns
- ğŸ”§ **Tool System** - Decorator-based tool definition vá»›i schema auto-generation
- ğŸ§  **Memory System** - Short-term, Long-term, Vector storage
- ğŸ”Œ **MCP Integration** - Káº¿t ná»‘i vá»›i MCP servers
- ğŸ“Š **Observability** - Logging, Tracing, Metrics
- âš¡ **Async-first** - Thiáº¿t káº¿ cho hiá»‡u suáº¥t cao

## CÃ i Ä‘áº·t

```bash
pip install agents-framework

# Vá»›i táº¥t cáº£ dependencies
pip install agents-framework[all]

# Chá»‰ Anthropic
pip install agents-framework[anthropic]

# Chá»‰ OpenAI
pip install agents-framework[openai]
```

## Quick Start

### 1. Simple Agent

```python
import asyncio
from agents_framework.llm.base import LLMConfig, Message, MessageRole
from agents_framework.llm.providers.openai import OpenAIProvider
from agents_framework.tools.base import tool
from agents_framework.tools.registry import ToolRegistry

# Äá»‹nh nghÄ©a tool
@tool(name="calculator", description="TÃ­nh toÃ¡n")
def calculator(expression: str) -> str:
    return str(eval(expression))

# Cáº¥u hÃ¬nh LLM
config = LLMConfig(
    model="claude-opus-4.5",
    api_key="your-key",
    base_url="http://localhost:4141/v1",
)

async def main():
    provider = OpenAIProvider(config)
    registry = ToolRegistry()
    registry.register(calculator)

    messages = [
        Message(role=MessageRole.USER, content="TÃ­nh 5 + 3")
    ]

    response = await provider.generate(messages, tools=registry.to_definitions())
    print(response.content)

asyncio.run(main())
```

### 2. Multi-Agent Team

```python
from agents_framework.teams.router import MessageRouter, AgentMessage
from agents_framework.teams.registry import AgentRegistry

# Táº¡o registry
registry = AgentRegistry()
router = MessageRouter()

# ÄÄƒng kÃ½ agents
registry.register(researcher_agent, agent_id="researcher", role="researcher")
registry.register(writer_agent, agent_id="writer", role="writer")

# Route messages
message = AgentMessage(
    sender_id="supervisor",
    receiver_id="researcher",
    content="TÃ¬m kiáº¿m vá» AI"
)
await router.route(message)
```

### 3. MCP Integration

```python
from agents_framework.mcp.client import MCPClient, MCPClientConfig

config = MCPClientConfig(
    name="filesystem",
    command="npx",
    args=["-y", "@anthropic/mcp-server-filesystem", "/tmp"]
)

client = MCPClient(config)
await client.connect()

# List available tools
tools = await client.list_tools()

# Call a tool
result = await client.call_tool("read_file", path="/tmp/test.txt")
```

## Cáº¥u trÃºc Project

```
agents_framework/
â”œâ”€â”€ llm/              # LLM providers (OpenAI, Anthropic, Ollama)
â”œâ”€â”€ tools/            # Tool system
â”œâ”€â”€ memory/           # Memory backends
â”œâ”€â”€ teams/            # Multi-agent orchestration
â”œâ”€â”€ mcp/              # MCP client
â”œâ”€â”€ context/          # Context management
â”œâ”€â”€ execution/        # Agent execution loop
â”œâ”€â”€ observability/    # Logging, tracing, metrics
â””â”€â”€ skills/           # Reusable workflows
```

## Examples

Xem thÆ° má»¥c `examples/` Ä‘á»ƒ biáº¿t thÃªm vÃ­ dá»¥:

- `01_simple_agent.py` - Agent Ä‘Æ¡n giáº£n vá»›i tools
- `02_research_team.py` - Team Ä‘a agent (Supervisor pattern)
- `03_mcp_integration.py` - TÃ­ch há»£p MCP servers

## Configuration

### OpenAI-Compatible Endpoint

```python
config = LLMConfig(
    model="claude-opus-4.5",
    api_key="your-key",
    base_url="http://localhost:4141/v1",
    temperature=0.7,
    max_tokens=4096,
    extra_params={
        "thinking": {"type": "enabled", "budget_tokens": 10000},
    },
)
```

## License

MIT
